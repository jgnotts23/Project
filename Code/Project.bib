Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Kim2018,
abstract = {In supervised machine learning for author name disambiguation, negative training data are often dominantly larger than positive training data. This paper examines how the ratios of negative to positive training data can affect the performance of machine learning algorithms to disambiguate author names in bibliographic records. On multiple labeled datasets, three classifiers - Logistic Regression, Na$\backslash$"ive Bayes, and Random Forest - are trained through representative features such as coauthor names, and title words extracted from the same training data but with various positive-negative training data ratios. Results show that increasing negative training data can improve disambiguation performance but with a few percent of performance gains and sometimes degrade it. Logistic Regression and Na$\backslash$"ive Bayes learn optimal disambiguation models even with a base ratio (1:1) of positive and negative training data. Also, the performance improvement by Random Forest tends to quickly saturate roughly after 1:10 {\~{}} 1:15. These findings imply that contrary to the common practice using all training data, name disambiguation algorithms can be trained using part of negative training data without degrading much disambiguation performance while increasing computational efficiency. This study calls for more attention from author name disambiguation scholars to methods for machine learning from imbalanced data.},
author = {Kim, Jinseok and Kim, Jenna},
doi = {10.1007/s11192-018-2865-9},
file = {:home/jacob/Downloads/1808.00525.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Author name disambiguation,Imbalanced training data,Negative training data,Supervised machine learning},
number = {1},
pages = {511--526},
title = {{The impact of imbalanced training data on machine learning for author name disambiguation}},
volume = {117},
year = {2018}
}
@article{Xu2004,
abstract = {With the exponential growth in the production creation of multimedia data, there is an increasing need for video semantic analysis. Audio, as a significant part of video, provides important cues to human perception when humans are browsing and understanding video contents. To detect semantic content by useful audio information, we introduce audio keywords which are sets of specific audio sounds related to semantic events. In our previous work, we designed a hierarchical Support Vector Machine (SVM) classifier for audio keyword identification. However, a weakness of our previous work is that audio signals are artificially segmented into 20 ms frames for frame-based SVM identification without any contextual information. In this paper, we propose a classification method based on Hidden Markov Modal (HMM) for audio keyword identification as an improved work instead of using hierarchical SVM classifier. Choosing HMM is motivated by the successful story of HMM in speech recognition. Unlike the frame-based SVM classification followed by major voting, our proposed HMM-based classifiers treat specific sound as a continuous time series data and employ hidden states transition to capture context information. In particular, we study how to find an effective HMM, i.e., determining topology, observation vectors and statistical parameters of HMM. We also compare different HMM structures with different hidden states, and adjust time series data with variable length. Experimental data includes 40 minutes basketball audio which comes from real-time sports games. Experimental results show that, for audio keyword generation, the proposed HMM-based method outperforms the previous hierarchical SVM. {\textcopyright} Springer-Verlag 2004.},
author = {Xu, Min and Duan, Ling Yu and Cai, Jianfei and Chia, Liang Tien and Xu, Changsheng and Tian, Qi},
file = {:home/jacob/Downloads/HMM-Based Audio Keyword Generation.pdf:pdf},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {by the successful story,choosing hmm is motivated,classification,followed by major voting,hierarchical,hmm in speech recognition,identification as an improved,of,our proposed hmm-based classifiers,svm classifier,treat spe-,unlike the frame-based svm,work instead of using},
pages = {566--574},
title = {{HMM-based audio keyword generation}},
volume = {3333},
year = {2004}
}
@article{Yeo2011,
abstract = {Voice recognition systems have become the important applications for speech recognition technology. In this paper, an animal identification (ID) detection system based on animal voice pattern recognition algorithm has been developed. The developed animal voice recognition system uses the zero-cross-rate (ZCR), Mel-Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW) joint algorithms as the tools for recognizing the voice of the particular animal. ZCR is used for the end point detection of input voice such that the silence voice can be removed. MFCC is used for the process of feature extraction where a more compact and less redundant of the representative voice can be obtained from the input voice. While the voice pattern classification will be done by using DTW algorithm. The DTW voice pattern classification module is playing a very important role as it is used to get the optimal path between the input voice and the reference voice in the database. The obtained results show that the developed recognition system can be worked as expected.},
author = {Yeo, Che Yong and Al-Haddad, S. A.R. and Ng, Chee Kyun},
doi = {10.1109/CSPA.2011.5759872},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeo, Al-Haddad, Ng - 2011 - Animal voice recognition for identification (ID) detection system.pdf:pdf},
isbn = {9781612844145},
journal = {Proceedings - 2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011},
keywords = {Animal,DTW,MFCC,Voice Recognition,ZCR},
number = {Id},
pages = {198--201},
title = {{Animal voice recognition for identification (ID) detection system}},
year = {2011}
}
@article{Chapman1989,
author = {Chapman, C. A. and Chapman, L. J. and McLaughlin, R. L.},
doi = {10.1007/BF00378668},
file = {:home/jacob/Documents/Project/Data/Papers/Chapman1989{\_}Article{\_}MultipleCentralPlaceForagingBy.pdf:pdf},
issn = {1432-1939},
journal = {Oecologia},
keywords = {Ateles,Multiple central place foragers,Sleeping sites},
number = {4},
pages = {506--511},
title = {{Multiple central place foraging by spider monkeys: travel consequences of using many sleeping sites}},
volume = {79},
year = {1989}
}
@article{Sueur2018a,
author = {Sueur, Jerome},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sueur - 2018 - IO of sound with R (seewave).pdf:pdf},
pages = {1--8},
title = {{I/O of sound with R (seewave)}},
year = {2018}
}
@article{Stevens1937,
abstract = {A subjective scale for the measurement of pitch was constructed from determinations of the half‐value of pitches at various frequencies. This scale differs from both the musical scale and the frequency scale, neither of which is subjective. Five observers fractionated tones of 10 different frequencies at a loudness level of 60 db. From these fractionations a numerical scale was constructed which is proportional to the perceived magnitude of subjective pitch. In numbering the scale the 1000‐cycle tone was assigned the pitch of 1000 subjective units (mels). The close agreement of the pitch scale with an integration of the differential thresholds (DL's) shows that, unlike the DL's for loudness, all DL's for pitch are of uniform subjective magnitude. The agreement further implies that pitch and differential sensitivity to pitch are both rectilinear functions of extent on the basilar membrane. The correspondence of the pitch scale and the experimentally determined location of the resonant areas of the basilar membrane suggests that, in cutting a pitch in half, the observer adjusts the tone until it stimulates a position half‐way from the original locus to the apical end of the membrane. Measurement of the subjective size of musical intervals (such as octaves) in terms of the pitch scale shows that the intervals become larger as the frequency of the mid‐point of the interval increases (except in the two highest audible octaves). This result confirms earlier judgments as to the relative size of octaves in different parts of the frequency range.},
author = {Stevens, S. S. and Volkmann, J. and Newman, E. B.},
journal = {Journal of the Acoustical Society of America},
number = {3},
pages = {185--190},
title = {{A Scale for the Measurement of the Psychological Magnitude Pitch}},
volume = {8},
year = {1937}
}
@article{Effects2015,
abstract = {Our understanding of the epidemiology, risk factors and natural history of pneumocystis pneumonia has increased enormously since the first patients with AIDS were described. It is clear that the major risk factor for developing pneumocystis pneumonia is immunosuppression as reflected by a circulating CD4 lymphocyte count of less than 200/$\mu$l. However, recent analyses indicate that persons with more than 200 CD4 cells may be at increased risk if they have symptomatic HIV disease. Thus, such patients are also candidates for prophylaxis. Also of note is the fact that whites have a higher risk of pneumocystis pneumonia than blacks. The use of prophylactic regimens clearly reduces the incidence of pneumocystis pneumonia as demonstrated by the results under 'real-world' conditions. The main affect appears to be a delay in the onset of the disease until the immune compromise is much more severe. Pneumocystis pneumonia rarely presents without respiratory symptoms-cough and/or shortness of breath. Although constitutional symptoms are present commonly, they are in themselves only rarely indicative of pneumocystis pneumonia. The most common radiographic feature of pneumocystis pneumonia is diffuse 'ground glass' infiltration. However, a variety of findings may be noted. These include focal infiltration, cysts, cavities, pneumothorax and miliary infiltration. Severe pneumocystis pneumonia may result in respiratory failure that necessitates mechanical ventilation. Over the years the prognosis for patients who require mechanical ventilation because of pneumocystis pneumonia has varied. In general, however, fewer patients seem to be requiring mechanical support. Other complications of the disease include chronic pneumothorax and chronic airways obstruction. Both of these conditions can be very difficult to manage.},
author = {Effects, Digital Audio},
doi = {10.13140/RG.2.1.1471.4640},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Effects - 2015 - AN EVALUATION OF AUDIO FEATURE EXTRACTION TOOLBOXES David Moffat , David Ronan , Joshua D . Reiss Center for Digital Mu.pdf:pdf},
issn = {1071-6564},
pages = {1--7},
title = {{AN EVALUATION OF AUDIO FEATURE EXTRACTION TOOLBOXES David Moffat , David Ronan , Joshua D . Reiss Center for Digital Music Queen Mary University of London Mile End Road}},
year = {2015}
}
@article{ZamoraGutierrez2016,
abstract = {* Monitoring global biodiversity is critical for understanding responses to anthropogenic change, but biodiversity monitoring is often biased away from tropical, megadiverse areas that are experiencing more rapid environmental change. Acoustic surveys are increasingly used to monitor biodiversity change, especially for bats as they are important indicator species and most use sound to detect, localise and classify objects. However, using bat acoustic surveys for monitoring poses several challenges, particularly in megadiverse regions. Many species lack reference recordings, some species have high call similarity or differ in call detectability, and quantitative classification tools, such as machine learning algorithms, have rarely been applied to data from these areas. * Here, we collate a reference call library for bat species that occur in a megadiverse country, Mexico. We use 4685 search-phase calls from 1378 individual sequences of 59 bat species to create automatic species identification tools generated by machine learning algorithms (Random Forest). We evaluate the improvement in species-level classification rates gained by using hierarchical classifications, reflecting either taxonomic or ecological constraints (guilds) on call design, and examine how classification rate accuracy changes at different hierarchical levels (family, genus and guild). * Species-level classification of calls had a mean accuracy of 66{\%}, and the use of hierarchies improved mean species-level classification accuracy by up to 6{\%} (species within families 72{\%}, species within genera 71{\textperiodcentered}2{\%} and species within guilds 69{\textperiodcentered}1{\%}). Classification accuracy to family, genus and guild-level was 91{\textperiodcentered}7{\%}, 77{\textperiodcentered}8{\%} and 82{\textperiodcentered}5{\%}, respectively. * The bioacoustic identification tools we have developed are accurate for rapid biodiversity assessments in a megadiverse region and can also be used effectively to classify species at broader taxonomic or ecological levels. This flexibility increases their usefulness when there are incomplete species reference recordings and also offers the opportunity to characterise and track changes in bat community structure. Our results show that bat bioacoustic surveys in megadiverse countries have more potential than previously thought to monitor biodiversity changes and can be used to direct further developments of bioacoustic monitoring programs in Mexico.},
author = {Zamora-Gutierrez, Veronica and Lopez-Gonzalez, Celia and {MacSwiney Gonzalez}, M. Cristina and Fenton, Brock and Jones, Gareth and Kalko, Elisabeth K.V. and Puechmaille, Sebastien J. and Stathopoulos, Vassilios and Jones, Kate E.},
doi = {10.1111/2041-210X.12556},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zamora-Gutierrez et al. - 2016 - Acoustic identification of Mexican bats based on taxonomic and ecological constraints on call design.pdf:pdf},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Neotropical,acoustic identification,guild,hierarchical classification,machine learning,random forest,whispering bats},
number = {9},
pages = {1082--1091},
title = {{Acoustic identification of Mexican bats based on taxonomic and ecological constraints on call design}},
volume = {7},
year = {2016}
}
@misc{Cuaron2008,
author = {Cuar{\'{o}}n, A. D. and Morales, A. and Shedden, A. and Rodriquez-Luna, E. and de Grammont, P. C. and Cortes-Ortiz, L.},
booktitle = {The IUCN Red List of Theatened Species},
file = {:home/jacob/Documents/Project/Data/Papers/10.2305{\_}IUCN.UK.2008.RLTS.T2279A9387270.en.pdf:pdf},
pages = {1--15},
title = {{Ateles geoffroyi , Geoffroy's Spider Monkey}},
url = {http://dx.doi.org/10.2305/IUCN.UK.2008.RLTS.T2279A9387270.en{\%}0ACopyright:},
urldate = {2019-07-22},
year = {2008}
}
@article{Kalan2016,
author = {Kalan, Ammie K and Piel, Alex K and Mundry, Roger and Wittig, Roman M and Boesch, Christophe and K{\"{u}}hl, Hjalmar S},
doi = {10.1186/s12983-016-0167-8},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalan et al. - 2016 - Passive acoustic monitoring reveals group ranging and territory use a case study of wild chimpanzees (Pan troglod.pdf:pdf},
isbn = {1298301601678},
issn = {1742-9994},
journal = {Frontiers in Zoology},
keywords = {Animal communication,Autonomous recording unit,Bio,animal communication,autonomous recording unit,bioacoustics,buttress drumming,loud calls},
number = {34},
pages = {1--11},
publisher = {Frontiers in Zoology},
title = {{Passive acoustic monitoring reveals group ranging and territory use : a case study of wild chimpanzees (Pan troglodytes)}},
url = {http://dx.doi.org/10.1186/s12983-016-0167-8},
volume = {13},
year = {2016}
}
@article{Astaras2017,
author = {Astaras, Christos and Linder, Joshua M. and Wrege, Peter and Orume, Robinson Diotoh and Macdonald, David W.},
doi = {10.1002/fee.1495},
file = {:home/jacob/Downloads/PassiveacousticmonitoringasalawenforcementtoolforAfrotropicalrainforests-Astarasetal.2017.pdf:pdf},
issn = {15409309},
journal = {Frontiers in Ecology and the Environment},
number = {5},
pages = {233--234},
title = {{Passive acoustic monitoring as a law enforcement tool for Afrotropical rainforests}},
volume = {15},
year = {2017}
}
@article{Clark1993,
author = {Clark, Adam P and Wrangham, Richard W},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clark, Wrangham - 1993 - Acoustic Analysis of Wild Chimpanzee Pant Hoots Do Kibale Forest Chimpanzees Have an Acoustically Distinct Foo.pdf:pdf},
journal = {American Journal of Primatology},
keywords = {acoustic analysis,chimpanzee,pant hoot,semanticity},
pages = {99--109},
title = {{Acoustic Analysis of Wild Chimpanzee Pant Hoots : Do Kibale Forest Chimpanzees Have an Acoustically Distinct Food Arrival Pant Hoot?}},
volume = {31},
year = {1993}
}
@article{Mielke2013,
author = {Mielke, Alexander and Zuberb{\"{u}}hler, Klaus},
doi = {10.1016/j.anbehav.2013.04.017},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mielke, Zuberb{\"{u}}hler - 2013 - A method for automated individual, species and call type recognition in free-ranging animals.pdf:pdf},
issn = {0003-3472},
journal = {Animal Behaviour},
number = {2},
pages = {475--482},
publisher = {Elsevier Ltd},
title = {{A method for automated individual, species and call type recognition in free-ranging animals}},
url = {http://dx.doi.org/10.1016/j.anbehav.2013.04.017},
volume = {86},
year = {2013}
}
@article{Heinicke2015,
author = {Heinicke, Stefanie and Kalan, Ammie K and Wagner, Oliver J J and Mundry, Roger and Lukashevich, Hannah and Kuhl, Hjalmar S.},
doi = {10.1111/2041-210X.12384},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heinicke et al. - 2015 - Assessing the performance of a semi-automated acoustic monitoring system for primates.pdf:pdf},
journal = {Methods in Ecology and Evolution},
pages = {753--763},
title = {{Assessing the performance of a semi-automated acoustic monitoring system for primates}},
volume = {6},
year = {2015}
}
@article{Goeau2016,
abstract = {The LifeCLEF bird identification challenge provides a large-scale testbed for the system-oriented evaluation of bird species identifi-cation based on audio recordings. One of its main strength is that the data used for the evaluation is collected through Xeno-Canto, the largest network of bird sound recordists in the world. This makes the task closer to the conditions of a real-world application than previous, similar initia-tives. The main novelty of the 2016-th edition of the challenge was the inclusion of soundscape recordings in addition to the usual xeno-canto recordings that focus on a single foreground species. This paper reports the methodology of the conducted evaluation, the overview of the sys-tems experimented by the 6 participating research groups and a synthetic analysis of the obtained results.},
author = {Go{\"{e}}au, Herv{\'{e}} and Glotin, Herv{\'{e}} and Vellinga, Willem-Pier and Planqu{\'{e}}, Robert and Joly, Alexis},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Go{\"{e}}au et al. - 2016 - LifeCLEF Bird Identification Task 2016 The arrival of Deep learning.pdf:pdf},
journal = {Working Notes of CLEF 2016 - Conference and Labs of the Evaluation forum},
keywords = {LifeCLEF,audio,benchmark,bioacoustics,bird,call,collection,eco-logical monitoring,evaluation,fine-grained classification,iden-tification,retrieval,song,species},
pages = {440--449},
title = {{LifeCLEF Bird Identification Task 2016: The arrival of Deep learning.}},
url = {https://hal.archives-ouvertes.fr/hal-01373779/document},
year = {2016}
}
@article{Sueur2018,
abstract = {R topics document},
author = {Sueur, J{\'{e}}r{\^{o}}me and Aubin, Thierry and Simonis, Caroline and Lellouch, Laurent and Brown, Ethan C. and Depraetere, Marion and Desjonqueres, Camille and Fabianek, Francois and Gasc, Amandine and Kasten, Eric and LaZerte, Stefanie and Lees, Jonathan and Marchal, Jean and Pavoine, Sandrine and Pinaud, David and Stotz, Alicia and Villanueva-Rivera, Luis J. and Ross, Zev and Witthoft, Carl G. and Zhivomirov, Hristo},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sueur et al. - 2018 - Sound Analysis and Synthesis, Package 'seewave'.pdf:pdf},
keywords = {2D and 3D spec-trograms and many other analyses Li,Alicia Stotz [ctrb],Amandine Gasc [ctrb],Author Jerome Sueur {\textless}sueur@mnhnfr{\textgreater} [cre,Camille Desjonqueres [ctrb],Carl G Witthoft [ctrb],Caroline Simonis [au],David Pinaud [ctrb],Eric Kasten [ctrb],Ethan C Brown [ctrb],Francois Fabianek [ctrb],Hristo Zhivomirov [ctrb] Maintainer Jerome Sueur {\textless},Jean Marchal [ctrb],Jonathan Lees [ctrb],Laurent Lellouch [main ctrb],Luis J Villanueva-Rivera [ctrb],Marion Depraetere [ctrb],Sandrine Pavoine [ctrb],Stefanie LaZerte [ctrb],Thierry Aubin [au],Zev Ross [ctrb],analytic signal,au],cross correlation and autocorrela-tion,displaying,dominant frequency,editing and synthesiz-ing time waves (particularly,entropy,fftw,frequency coherence,ggplot2,grDevices,manipulating,phonTools,resonance quality factor,rgl,rpanel,signal ZipData no Description Functions for analys,spectral content,stats,tuneR Suggests audio,utils,zero-crossing},
pages = {201},
title = {{Sound Analysis and Synthesis, Package 'seewave'}},
url = {http://rug.mnhn.fr/seewave},
year = {2018}
}
@article{Owren1993,
author = {Owren, Michael J and Linker, Christopher D and Rowe, Matthew P},
doi = {10.1121/1.407791},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Owren, Linker, Rowe - 1993 - Acoustic features of tonal ‘‘grunt'' calls in baboons.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
pages = {1822--1823},
title = {{Acoustic features of tonal ‘‘grunt'' calls in baboons}},
volume = {94},
year = {1993}
}
@article{Fanin2018,
abstract = {{\textcopyright} 2017 The Author(s). Understanding how loss of biodiversity affects ecosystem functioning, and thus the delivery of ecosystem goods and services, has become increasingly necessary in a changing world. Considerable recent attention has focused on predicting how biodiversity loss simultaneously impacts multiple ecosystem functions (that is, ecosystem multifunctionality), but the ways in which these effects vary across ecosystems remain unclear. Here, we report the results of two 19-year plant diversity manipulation experiments, each established across a strong environmental gradient. Although the effects of plant and associated fungal diversity loss on individual functions frequently differed among ecosystems, the consequences of biodiversity loss for multifunctionality were relatively invariant. However, the context-dependency of biodiversity effects also worked in opposing directions for different individual functions, meaning that similar multifunctionality values across contrasting ecosystems could potentially mask important differences in the effects of biodiversity on functioning among ecosystems. Our findings highlight that an understanding of the relative contribution of species or functional groups to individual ecosystem functions among contrasting ecosystems and their interactions (that is, complementarity versus competition) is critical for guiding management efforts aimed at maintaining ecosystem multifunctionality and the delivery of multiple ecosystem services.},
author = {Fanin, Nicolas and Gundale, Michael J. and Farrell, Mark and Ciobanu, Marcel and Baldock, Jeff A. and Nilsson, Marie Charlotte and Kardol, Paul and Wardle, David A.},
doi = {10.1038/s41559-017-0415-0},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fanin et al. - 2018 - Consistent effects of biodiversity loss on multifunctionality across contrasting ecosystems(2).pdf:pdf},
issn = {2397334X},
journal = {Nature Ecology and Evolution},
number = {2},
pages = {269--278},
publisher = {Springer US},
title = {{Consistent effects of biodiversity loss on multifunctionality across contrasting ecosystems}},
url = {http://dx.doi.org/10.1038/s41559-017-0415-0},
volume = {2},
year = {2018}
}
@inproceedings{Liao2016,
author = {Liao, Z. and Carneiro, G.},
booktitle = {IEEE Winter Conference on Applications of Computer Vision (WACV)},
file = {:home/jacob/Downloads/226.pdf:pdf},
pages = {1--8},
title = {{On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units}},
year = {2016}
}
@article{Zeppelzauer2010,
author = {Zeppelzauer, Matthias and Breiteneder, Christian},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeppelzauer, Breiteneder - 2010 - Mitrović{\_}2010a{\_}Features for content-based audio retrieval.pdf.pdf:pdf},
pages = {71--150},
title = {{Mitrović{\_}2010a{\_}Features for content-based audio retrieval.pdf}},
volume = {78},
year = {2010}
}
@article{Steen2012,
author = {Steen, Kim Arild and Therkildsen, Ole Roland and Karstoft, Henrik and Green, Ole},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steen et al. - 2012 - Wildlife Communication.pdf:pdf},
number = {January},
title = {{Wildlife Communication}},
year = {2012}
}
@misc{Chollet2016,
author = {Chollet, Francois},
booktitle = {The Keras Blog},
title = {{Building powerful image classification models using very little data}},
url = {https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html},
urldate = {18/08/19},
year = {2016}
}
@book{.2554,
author = {{นคเรศ รังควัต.}},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/.pdf:pdf},
isbn = {9780499284105},
title = {{No Titleกระบวนการสื่อสารกับการยอมรับปรัชญาเศรษฐกิจพอเพียงของเกษตรกร ในจังหวัดเชียงใหม่}},
year = {2554}
}
@article{Lecun2015,
author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lecun, Bengio, Hinton - 2015 - DeepLearning{\_}2015{\_}YannLeCunnYoshuaBengioGeoffreyHinton.pdf:pdf},
title = {{DeepLearning{\_}2015{\_}YannLeCunnYoshuaBengioGeoffreyHinton}},
year = {2015}
}
@article{Allan2015,
abstract = {{\textcopyright} 2015 John Wiley {\&} Sons Ltd/CNRS. Global change, especially land-use intensification, affects human well-being by impacting the delivery of multiple ecosystem services (multifunctionality). However, whether biodiversity loss is a major component of global change effects on multifunctionality in real-world ecosystems, as in experimental ones, remains unclear. Therefore, we assessed biodiversity, functional composition and 14 ecosystem services on 150 agricultural grasslands differing in land-use intensity. We also introduce five multifunctionality measures in which ecosystem services were weighted according to realistic land-use objectives. We found that indirect land-use effects, i.e. those mediated by biodiversity loss and by changes to functional composition, were as strong as direct effects on average. Their strength varied with land-use objectives and regional context. Biodiversity loss explained indirect effects in a region of intermediate productivity and was most damaging when land-use objectives favoured supporting and cultural services. In contrast, functional composition shifts, towards fast-growing plant species, strongly increased provisioning services in more inherently unproductive grasslands.},
author = {Allan, Eric and Manning, Pete and Alt, Fabian and Binkenstein, Julia and Blaser, Stefan and Bl{\"{u}}thgen, Nico and B{\"{o}}hm, Stefan and Grassein, Fabrice and H{\"{o}}lzel, Norbert and Klaus, Valentin H. and Kleinebecker, Till and Morris, E. Kathryn and Oelmann, Yvonne and Prati, Daniel and Renner, Swen C. and Rillig, Matthias C. and Schaefer, Martin and Schloter, Michael and Schmitt, Barbara and Sch{\"{o}}ning, Ingo and Schrumpf, Marion and Solly, Emily and Sorkau, Elisabeth and Steckel, Juliane and Steffen-Dewenter, Ingolf and Stempfhuber, Barbara and Tschapka, Marco and Weiner, Christiane N. and Weisser, Wolfgang W. and Werner, Michael and Westphal, Catrin and Wilcke, Wolfgang and Fischer, Markus},
doi = {10.1111/ele.12469},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allan et al. - 2015 - Land use intensification alters ecosystem multifunctionality via loss of biodiversity and changes to functional co.pdf:pdf},
issn = {14610248},
journal = {Ecology Letters},
keywords = {Biodiversity-ecosystem functioning,Ecosystem services,Global change,Land use,Multifunctionality},
number = {8},
pages = {834--843},
title = {{Land use intensification alters ecosystem multifunctionality via loss of biodiversity and changes to functional composition}},
volume = {18},
year = {2015}
}
@article{Arroyo-Rodriguez2017,
abstract = {With the extant of tropical forest degradation, primates increasingly inhabit forest patches embedded in anthropogenic matrices. Such matrices are composed of different land cover types (e.g., agricultural lands and cattle pastures), but large uncertainty remains about the ability of primates to use these land covers. Here, we assessed the use of the landscape matrix by spider monkeys (Ateles geoffroyi) in 13 forest sites from three countries (Mexico, Costa Rica, and El Salvador). Based on ad libitum records from {\textgreater}212 months of field observations, we found that spider monkeys used four types of land covers for feeding or traveling: secondary vegetation, isolated trees, tree crops, and vegetation corridors. Secondary vegetation was more frequently used than the other land covers. The number of land covers present in the matrix was positively related to the number of land covers used for traveling and feeding. Monkeys consumed 53 plant species in the matrix, mostly native and old-growth or late-successional...},
author = {Arroyo-Rodr{\'{i}}guez, V{\'{i}}ctor and P{\'{e}}rez-Elissetche, Gloria Karina and Ord{\'{o}}{\~{n}}ez-G{\'{o}}mez, Jos{\'{e}} D. and Gonz{\'{a}}lez-Zamora, Arturo and Chaves, {\'{O}}scar M. and S{\'{a}}nchez-L{\'{o}}pez, S{\`{o}}nia and Chapman, Colin A. and Morales-Hern{\'{a}}ndez, Karenina and Pablo-Rodr{\'{i}}guez, Miriam and Ramos-Fern{\'{a}}ndez, Gabriel},
doi = {10.1177/1940082917719788},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arroyo-Rodr{\'{i}}guez et al. - 2017 - Spider Monkeys in Human-Modified Landscapes.pdf:pdf},
issn = {1940-0829},
journal = {Tropical Conservation Science},
keywords = {atelidae,behavioral flexibility,compositional heterogeneity,corridors,fragmentation,habitat loss,land sharing,landscape},
pages = {194008291771978},
title = {{Spider Monkeys in Human-Modified Landscapes}},
volume = {10},
year = {2017}
}
@article{Lucas2015,
author = {Lucas, Tim C D and Moorcroft, Elizabeth A and Freeman, Robin and Rowcliffe, J Marcus and Jones, Kate E},
doi = {10.1111/2041-210X.12346},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lucas et al. - 2015 - A generalised random encounter model for estimating animal density with remote sensor data.pdf:pdf},
journal = {Methods in Ecology and Evolution},
pages = {500--509},
title = {{A generalised random encounter model for estimating animal density with remote sensor data}},
volume = {6},
year = {2015}
}
@article{Ramos-Fernandez2010,
abstract = {Spider monkeys are one of the most widespread New World primate genera, ranging from southern Mexico to Bolivia. Although they are common in zoos, spider monkeys are traditionally very difficult to study in the wild, because they are fast moving, live high in the canopy and are almost always found in small subgroups that vary in size and composition throughout the day. The past decade has seen an expansion in research being carried out on this genus and this book is an assimilation of both published, and new and previously unpublished, research. It is a comprehensive source of information for academic researchers and graduate students interested in primatology, evolutionary anthropology and behavioral ecology and covers topics such as taxonomy, diet, sexuality and reproduction, and conservation.},
author = {Ramos-Fern{\'{a}}ndez, Gabriel},
doi = {10.1017/cbo9780511721915.008},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramos-Fern{\'{a}}ndez - 2010 - Communication in spider monkeys the function and mechanisms underlying the use of the whinny.pdf:pdf},
isbn = {9780511721915},
journal = {Spider Monkeys},
number = {January},
pages = {220--235},
title = {{Communication in spider monkeys: the function and mechanisms underlying the use of the whinny}},
year = {2010}
}
@article{Norouzzadeh2017,
abstract = {Having accurate, detailed, and up-to-date information about the location and behavior of animals in the wild would revolutionize our ability to study and conserve ecosystems. We investigate the ability to automatically, accurately, and inexpensively collect such data, which could transform many fields of biology, ecology, and zoology into "big data" sciences. Motion sensor "camera traps" enable collecting wildlife pictures inexpensively, unobtrusively, and frequently. However, extracting information from these pictures remains an expensive, time-consuming, manual task. We demonstrate that such information can be automatically extracted by deep learning, a cutting-edge type of artificial intelligence. We train deep convolutional neural networks to identify, count, and describe the behaviors of 48 species in the 3.2-million-image Snapshot Serengeti dataset. Our deep neural networks automatically identify animals with over 93.8{\%} accuracy, and we expect that number to improve rapidly in years to come. More importantly, if our system classifies only images it is confident about, our system can automate animal identification for 99.3{\%} of the data while still performing at the same 96.6{\%} accuracy as that of crowdsourced teams of human volunteers, saving more than 8.4 years (at 40 hours per week) of human labeling effort (i.e. over 17,000 hours) on this 3.2-million-image dataset. Those efficiency gains immediately highlight the importance of using deep neural networks to automate data extraction from camera-trap images. Our results suggest that this technology could enable the inexpensive, unobtrusive, high-volume, and even real-time collection of a wealth of information about vast numbers of animals in the wild.},
archivePrefix = {arXiv},
arxivId = {1703.05830},
author = {Norouzzadeh, Mohammed Sadegh and Nguyen, Anh and Kosmala, Margaret and Swanson, Ali and Palmer, Meredith and Packer, Craig and Clune, Jeff},
doi = {10.1073/pnas.1719367115},
eprint = {1703.05830},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Norouzzadeh et al. - 2018 - Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning.pdf:pdf},
journal = {Proceedings of the National Academy of Sciences},
number = {25},
pages = {716--725},
title = {{Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning}},
volume = {115},
year = {2018}
}
@article{Mohamed2010,
author = {Mohamed, Abdel-rahman and Dahl, George E and Hinton, Geoffrey},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton - 2010 - Acoustic Modeling using Deep Belief Networks.pdf:pdf},
journal = {IEEE Signal Processing Letters},
pages = {1--10},
title = {{Acoustic Modeling using Deep Belief Networks}},
year = {2010}
}
@article{Reason2016,
abstract = {Robust information on bat species distribution and activity is lacking. With developments in passive full spectrum bat detectors and software packages for automating the analysis of sound files, there is the potential to analyse large volumes of acoustic data and thus inform a better understanding of bat ecology and distribution. However, for anyone making use of such tools, it is essential to understand the limitations and likely biases of the software, in order to make an informed interpretation. Bat activity Defining bat activity (as recorded by detectors) Relative bat activity can be measured from the search-phase echolocation calls of bats or, more commonly, from 'bat passes/sequences' – where a pass/sequence is a series of calls belonging to an individual bat. • Unless manually determined by a human observer, the way bat calls are divided into bat passes is defined by the automatic identification (Auto-ID) software selected. • 'Bat pass' is therefore a parameter that needs to be defined for each study. • The number of bat calls or bat passes does not directly relate to the number of bats in a location, although recent statistical approaches may now be able to model this directly 1 . It is important to consider carefully (and possibly ground truth) how relative bat activity will be interpreted. Defining bat passes • Bat passes are often defined by a minimum number of calls in a series and/or the time between calls or a series of calls (the inter-pulse interval). • For example, a bat pass could be any call or series of calls separated by more than one second from another call or series of calls, although other definitions state that a bat pass comprises at least two calls in a series. • The definition of bat passes therefore needs to be determined before analysis, clearly stated, and kept consistent throughout a project. • Some software (e.g. iBatsID using SonoBat-generated parameters) classifies each call rather than a series of calls, so further processing is required to determine the number of bat passes and to evaluate the most likely species based on how these are assigned over the entire series.},
author = {Reason, Paola F. and Newson, Stuart E and Jones, Kate E.},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reason, Newson, Jones - 2016 - Recommendations for using automatic bat identification software with full spectrum recordings.pdf:pdf},
journal = {Bat Conservation Trust},
keywords = {automatic identification,bats,full spectrum},
number = {April},
pages = {1--4},
title = {{Recommendations for using automatic bat identification software with full spectrum recordings}},
year = {2016}
}
@article{Giannakopoulos2015,
abstract = {Audio information plays a rather important role in the increasing digital content that is available today, resulting in a need for methodologies that automatically analyze such content: audio event recognition for home automations and surveillance systems, speech recognition, music information retrieval, multimodal analysis (e.g. audio-visual analysis of online videos for content-based recommendation), etc. This paper presents pyAudioAnalysis, an open-source Python library that provides a wide range of audio analysis procedures including: feature extraction, classification of audio signals, supervised and unsupervised segmentation and content visualization. pyAudioAnalysis is licensed under the Apache License and is available at GitHub (https://github.com/tyiannak/pyAudioAnalysis/). Here we present the theoretical background behind the wide range of the implemented methodologies, along with evaluation metrics for some of the methods. pyAudioAnalysis has been already used in several audio analysis research applications: smart-home functionalities through audio event detection, speech emotion recognition, depression classification based on audio-visual features, music segmentation, multimodal content-based movie recommendation and health applications (e.g. monitoring eating habits). The feedback provided from all these particular audio applications has led to practical enhancement of the library.},
author = {Giannakopoulos, Theodoros},
doi = {10.1371/journal.pone.0144610},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giannakopoulos - 2015 - PyAudioAnalysis An open-source python library for audio signal analysis.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--17},
title = {{PyAudioAnalysis: An open-source python library for audio signal analysis}},
url = {http://dx.doi.org/10.1371/journal.pone.0144610},
volume = {10},
year = {2015}
}
@article{Newbold2015,
abstract = {Human activities, especially conversion and degradation of habitats, are causing global biodiversity declines. How local ecological assemblages are responding is less clear--a concern given their importance for many ecosystem functions and services. We analysed a terrestrial assemblage database of unprecedented geographic and taxonomic coverage to quantify local biodiversity responses to land use and related changes. Here we show that in the worst-affected habitats, these pressures reduce within-sample species richness by an average of 76.5{\%}, total abundance by 39.5{\%} and rarefaction-based richness by 40.3{\%}. We estimate that, globally, these pressures have already slightly reduced average within-sample richness (by 13.6{\%}), total abundance (10.7{\%}) and rarefaction-based richness (8.1{\%}), with changes showing marked spatial variation. Rapid further losses are predicted under a business-as-usual land-use scenario; within-sample richness is projected to fall by a further 3.4{\%} globally by 2100, with losses concentrated in biodiverse but economically poor countries. Strong mitigation can deliver much more positive biodiversity changes (up to a 1.9{\%} average increase) that are less strongly related to countries' socioeconomic status.},
author = {Newbold, Tim and Hudson, Lawrence N and Hill, Samantha L L and Contu, Sara and Lysenko, Igor and Senior, Rebecca A and B{\"{o}}rger, Luca and Bennett, Dominic J and Choimes, Argyrios and Collen, Ben and Day, Julie and {De Palma}, Adriana and D{\'{i}}az, Sandra and Echeverria-Londo{\~{n}}o, Susy and Edgar, Melanie J and Feldman, Anat and Garon, Morgan and Harrison, Michelle L K and Alhusseini, Tamera and Ingram, Daniel J and Itescu, Yuval and Kattge, Jens and Kemp, Victoria and Kirkpatrick, Lucinda and Kleyer, Michael and Correia, David Laginha Pinto and Martin, Callum D and Meiri, Shai and Novosolov, Maria and Pan, Yuan and Phillips, Helen R P and Purves, Drew W and Robinson, Alexandra and Simpson, Jake and Tuck, Sean L and Weiher, Evan and White, Hannah J and Ewers, Robert M and Mace, Georgina M and Scharlemann, J{\"{o}}rn P W and Purvis, Andy},
doi = {10.1038/nature14324},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newbold et al. - 2015 - Global effects of land use on local terrestrial biodiversity.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
number = {7545},
pages = {45--50},
pmid = {25832402},
title = {{Global effects of land use on local terrestrial biodiversity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25832402},
volume = {520},
year = {2015}
}
@article{Stowell2014,
abstract = {Automatic species classification of birds from their sound is a computational tool of increasing importance in ecology, conservation monitoring and vocal communication studies. To make classification useful in practice, it is crucial to improve its accuracy while ensuring that it can run at big data scales. Many approaches use acoustic measures based on spectrogram-type data, such as the Mel-frequency cepstral coefficient (MFCC) features which represent a manually-designed summary of spectral information. However, recent work in machine learning has demonstrated that features learnt automatically from data can often outperform manually-designed feature transforms. Feature learning can be performed at large scale and "unsupervised", meaning it requires no manual data labelling, yet it can improve performance on "supervised" tasks such as classification. In this work we introduce a technique for feature learning from large volumes of bird sound recordings, inspired by techniques that have proven useful in other domains. We experimentally compare twelve different feature representations derived from the Mel spectrum (of which six use this technique), using four large and diverse databases of bird vocalisations, with a random forest classifier. We demonstrate that MFCCs are of limited power in this context, leading to worse performance than the raw Mel spectral data. Conversely, we demonstrate that unsupervised feature learning provides a substantial boost over MFCCs and Mel spectra without adding computational complexity after the model has been trained. The boost is particularly notable for single-label classification tasks at large scale. The spectro-temporal activations learned through our procedure resemble spectro-temporal receptive fields calculated from avian primary auditory forebrain.},
author = {Stowell, Dan and Plumbley, Mark D.},
doi = {10.7717/peerj.488},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stowell, Plumbley - 2014 - Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning.pdf:pdf},
journal = {PeerJ},
keywords = {accepted 26 june 2014,bioacoustics,birds,birdsong,classification,machine learning,published 17 july 2014,submitted 25 may 2014,vocalisation},
pages = {1--31},
title = {{Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning}},
volume = {2},
year = {2014}
}
@article{VanRoosmalen1985,
author = {van Roosmalen, M. G. M.},
file = {:home/jacob/Documents/Project/Data/Papers/Habitat{\_}preferences{\_}diet{\_}feeding{\_}strategy{\_}and{\_}soci.pdf:pdf},
journal = {Acta Amazonica},
title = {{Habitat preferences, diet, feeding strategy and social organization of the black spider monkey (Ateles paniscus paniscus Linnaeus 1758) in Surinam}},
volume = {15},
year = {1985}
}
@article{Prince2019,
abstract = {{\textless}p{\textgreater}Conservation researchers require low-cost access to acoustic monitoring technology. However, affordable tools are often constrained to short-term studies due to high energy consumption and limited storage. To enable long-term monitoring, energy and space efficiency must be improved on such tools. This paper describes the development and deployment of three acoustic detection algorithms that reduce the power and storage requirements of acoustic monitoring on affordable, open-source hardware. The algorithms aim to detect bat echolocation, to search for evidence of an endangered cicada species, and also to collect evidence of poaching in a protected nature reserve. The algorithms are designed to run on AudioMoth: a low-cost, open-source acoustic monitoring device, developed by the authors and widely adopted by the conservation community. Each algorithm addresses a detection task of increasing complexity, implementing extra analytical steps to account for environmental conditions such as wind, analysing samples multiple times to prevent missed events, and incorporating a hidden Markov model for sample classification in both the time and frequency domain. For each algorithm, we report on real-world deployments carried out with partner organisations and also benchmark the hidden Markov model against a convolutional neural network, a deep-learning technique commonly used for acoustics. The deployments demonstrate how acoustic detection algorithms extend the use of low-cost, open-source hardware and facilitate a new avenue for conservation researchers to perform large-scale monitoring.{\textless}/p{\textgreater}},
author = {Prince, Peter and Hill, Andrew and {Pi{\~{n}}a Covarrubias}, Evelyn and Doncaster, Patrick and Snaddon, Jake L and Rogers, Alex},
doi = {10.3390/s19030553},
issn = {14248220},
journal = {Sensors (Basel, Switzerland)},
keywords = {acoustics,bioacoustics,conservation,ecology,machine learning},
number = {3},
pages = {1--23},
title = {{Deploying Acoustic Detection Algorithms on Low-Cost, Open-Source Acoustic Sensors for Environmental Monitoring}},
volume = {19},
year = {2019}
}
@article{Ceballos2015,
author = {Ceballos, Gerardo and Ehrlich, Paul R and Barnosky, Anthony D and Garc{\'{i}}a, Andr{\'{e}}s and Pringle, Robert M and Palmer, Todd M},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ceballos et al. - 2015 - Accelerated modern human-induced species losses Entering the sixth mass extinction.pdf:pdf},
issn = {{\textless}null{\textgreater}},
journal = {Science Advances},
number = {5},
pages = {1--5},
title = {{Accelerated modern human-induced species losses: Entering the sixth mass extinction}},
volume = {1},
year = {2015}
}
@article{Doherty2016,
abstract = {Invasive species threaten biodiversity globally, and invasive mammalian predators are particularly damaging, having contributed to considerable species decline and extinction. We provide a global metaanalysis of these impacts and reveal their full extent. Invasive predators are implicated in 87 bird, 45 mammal, and 10 reptile species extinctions-58{\%} of these groups' contemporary extinctions worldwide. These figures are likely underestimated because 23 critically endangered species that we assessed are classed as "possibly extinct." Invasive mammalian predators endanger a further 596 species at risk of extinction, with cats, rodents, dogs, and pigs threatening the most species overall. Species most at risk from predators have high evolutionary distinctiveness and inhabit insular environments. Invasive mammalian predators are therefore important drivers of irreversible loss of phylogenetic diversity worldwide. That most impacted species are insular indicates that management of invasive predators on islands should be a global conservation priority. Understanding and mitigating the impact of invasive mammalian predators is essential for reducing the rate of global biodiversity loss.},
author = {Doherty, Tim S. and Glen, Alistair S. and Nimmo, Dale G. and Ritchie, Euan G. and Dickman, Chris R.},
doi = {10.1073/pnas.1602480113},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doherty et al. - 2016 - Invasive predators and global biodiversity loss.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {40},
pages = {11261--11265},
title = {{Invasive predators and global biodiversity loss}},
volume = {113},
year = {2016}
}
@article{Gillespie2013,
abstract = {PAMGUARD is open‐source, platform‐independent software to address the needs of developers and users of Passive Acoustic Monitoring (PAM) systems. For the PAM operator—marine mammal biologist, manager, or mitigator—PAMGUARD provides a flexible and easy‐to‐use suite of detection, localization, data management, and display modules. These provide a standard interface across different platforms with the flexibility to allow multiple detectors to be added, removed, and configured according to the species of interest and the hardware configuration on a particular project. For developers of PAM systems, an Application Programming Interface (API) has been developed which contains standard classes for the efficient handling of many types of data, interfaces to acquisition hardware and to databases, and a GUI framework for data display. PAMGUARD replicates and exceeds the capabilities of earlier real time monitoring programs such as the IFAW Logger Suite and Ishmael. Ongoing developments include improved real‐time location and automated species classification.},
author = {Gillespie, Douglas and Mellinger, David K. and Gordon, Jonathan and McLaren, David and Redmond, Paul and McHugh, Ronald and Trinder, Philip and Deng, Xiao‐Yan and Thode, Aaron},
doi = {10.1121/1.4808713},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gillespie et al. - 2013 - PAMGUARD Semiautomated, open source software for real‐time acoustic detection and localization of cetaceans.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {2547--2547},
title = {{PAMGUARD: Semiautomated, open source software for real‐time acoustic detection and localization of cetaceans.}},
volume = {125},
year = {2013}
}
@article{DeVos2015,
abstract = {A key measure of humanity's global impact is by how much it has increased species extinction rates. Familiar statements are that these are 100-1000 times pre-human or background extinction levels. Estimating recent rates is straightforward, but establishing a background rate for comparison is not. Previous researchers chose an approximate benchmark of 1 extinction per million species per year (E/MSY). We explored disparate lines of evidence that suggest a substantially lower estimate. Fossil data yield direct estimates of extinction rates, but they are temporally coarse, mostly limited to marine hard-bodied taxa, and generally involve genera not species. Based on these data, typical background loss is 0.01 genera per million genera per year. Molecular phylogenies are available for more taxa and ecosystems, but it is debated whether they can be used to estimate separately speciation and extinction rates. We selected data to address known concerns and used them to determine median extinction estimates from statistical distributions of probable values for terrestrial plants and animals. We then created simulations to explore effects of violating model assumptions. Finally, we compiled estimates of diversificationthe difference between speciation and extinction rates for different taxa. Median estimates of extinction rates ranged from 0.023 to 0.135 E/MSY. Simulation results suggested over- and under-estimation of extinction from individual phylogenies partially canceled each other out when large sets of phylogenies were analyzed. There was no evidence for recent and widespread pre-human overall declines in diversity. This implies that average extinction rates are less than average diversification rates. Median diversification rates were 0.05-0.2 new species per million species per year. On the basis of these results, we concluded that typical rates of background extinction may be closer to 0.1 E/MSY. Thus, current extinction rates are 1,000 times higher than natural background rates of extinction and future rates are likely to be 10,000 times higher.},
author = {{De Vos}, Jurriaan M. and Joppa, Lucas N. and Gittleman, John L. and Stephens, Patrick R. and Pimm, Stuart L.},
doi = {10.1111/cobi.12380},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Vos et al. - 2015 - Estimating the normal background rate of species extinction.pdf:pdf},
issn = {15231739},
journal = {Conservation Biology},
keywords = {Diversification rates,Extinction rate,Fossil record,Lineages through time,Molecular phylogenies},
number = {2},
pages = {452--462},
title = {{Estimating the normal background rate of species extinction}},
volume = {29},
year = {2015}
}
@unpublished{Lawson2019,
author = {Lawson, Jenna},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lawson - 2019 - Sounds of the Spider Monkey Using acoustics to investigate biodiversity, and land use and threats to the Geoffroy's(2).pdf:pdf},
pages = {1--35},
title = {{Sounds of the Spider Monkey : Using acoustics to investigate biodiversity, and land use and threats to the Geoffroy's spider monkey (Ateles geoffroyi) in Costa Rica}},
year = {2019}
}
@inproceedings{Glorot2011,
abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hy-perbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros, which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
doi = {10.1.1.208.6449},
eprint = {1502.03167},
file = {:home/jacob/Downloads/glorot11a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
pages = {315--323},
pmid = {28788938},
title = {{Deep Sparse Rectifier Neural Networks Xavier}},
url = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
volume = {15},
year = {2011}
}
@article{Blumstein2011,
author = {Blumstein, Daniel T and Mennill, Daniel J and Clemins, Patrick and Girod, Lewis and Yao, Kung and Patricelli, Gail and Deppe, Jill L and Krakauer, Alan H and Clark, Christopher and Cortopassi, Kathryn A and Hanser, Sean F and Mccowan, Brenda and Ali, Andreas M and Kirschel, Alexander N. G.},
doi = {10.1111/j.1365-2664.2011.01993.x},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blumstein et al. - 2011 - Acoustic monitoring in terrestrial environments using microphone arrays applications , technological consider.pdf:pdf},
journal = {Journal of Applied Ecology},
pages = {758--767},
title = {{Acoustic monitoring in terrestrial environments using microphone arrays : applications , technological considerations and prospectus}},
volume = {48},
year = {2011}
}
@article{Zilli2014,
abstract = {{\textless}p{\textgreater}In recent years, the field of computational sustainability has striven to apply artificial intelligence techniques to solve ecological and environmental problems. In ecology, a key issue for the safeguarding of our planet is the monitoring of biodiversity. Automated acoustic recognition of species aims to provide a cost-effective method for biodiversity monitoring. This is particularly appealing for detecting endangered animals with a distinctive call, such as the New Forest cicada. To this end, we pursue a crowdsourcing approach, whereby the millions of visitors to the New Forest, where this insect was historically found, will help to monitor its presence by means of a smartphone app that can detect its mating call. Existing research in the field of acoustic insect detection has typically focused upon the classification of recordings collected from fixed field microphones. Such approaches segment a lengthy audio recording into individual segments of insect activity, which are independently classified using cepstral coefficients extracted from the recording as features. This paper reports on a contrasting approach, whereby we use crowdsourcing to collect recordings via a smartphone app, and present an immediate feedback to the users as to whether an insect has been found. Our classification approach does not remove silent parts of the recording via segmentation, but instead uses the temporal patterns throughout each recording to classify the insects present. We show that our approach can successfully discriminate between the call of the New Forest cicada and similar insects found in the New Forest, and is robust to common types of environment noise. A large scale trial deployment of our smartphone app collected over 6000 reports of insect activity from over 1000 users. Despite the cicada not having been rediscovered in the New Forest, the effectiveness of this approach was confirmed for both the detection algorithm, which successfully identified the same cicada through the app in countries where the same species is still present, and of the crowdsourcing methodology, which collected a vast number of recordings and involved thousands of contributors.{\textless}/p{\textgreater}},
author = {Zilli, Davide and Parson, Oliver and Merrett, Geoff V. and Rogers, Alex},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zilli et al. - 2014 - A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
keywords = {Citizen Science, Artificial Intelligence, Machine},
pages = {805--827},
title = {{A hidden Markov model-based acoustic cicada detector for crowdsourced smartphone biodiversity monitoring}},
volume = {51},
year = {2014}
}
@article{Bello2014,
author = {Bello, Juan Pablo},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bello - 2014 - Sound Classification.pdf:pdf},
number = {April 2013},
pages = {37--41},
title = {{Sound Classification}},
year = {2014}
}
@article{Cartwright2017,
abstract = {Audio annotation is key to developing machine-listening systems; yet, effective ways to accurately and rapidly obtain crowdsourced audio annotations is understudied. In this work, we seek to quantify the relia-bility/redundancy trade-off in crowdsourced soundscape annotation, investigate how visualizations affect accuracy and efficiency, and characterize how performance varies as a function of audio characteristics. Using a controlled experiment, we varied sound visualizations and the complexity of soundscapes presented to human annotators. Results show that more complex audio scenes result in lower annotator agreement, and spectrogram visualizations are superior in producing higher quality annotations at lower cost of time and human labor. We also found recall is more affected than precision by soundscape complexity, and mistakes can be often attributed to certain sound event characteristics. These findings have implications not only for how we should design annotation tasks and interfaces for audio data, but also how we train and evaluate machine-listening systems.},
author = {Cartwright, Mark and Salamon, Justin and Williams, Alex and Mikloska, Stefanie and Macconnell, Duncan and Bello, Juan P and Seals, Ayanna and Law, Edith and Nov, Oded and Law, ; Edith},
doi = {10.1145/3134664},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cartwright et al. - 2017 - Seeing Sound Investigating the Effects of Visualizations and Complexity on Crowdsourced Audio Annotations.pdf:pdf},
journal = {Proc. ACM Hum.-Comput. Interact. 1, CSCW, Article},
keywords = {Annotation,Sound Event Detection},
number = {2},
pages = {29},
title = {{Seeing Sound: Investigating the Effects of Visualizations and Complexity on Crowdsourced Audio Annotations}},
volume = {29},
year = {2017}
}
@article{Camastra2009,
abstract = {One of the most interesting technological phenomena in recent years is the diffusion of consumer electronic products with constantly increasing acquisition, storage and processing power. As an example, consider the evolution of digital cameras: the first models available in the market in the early nineties produced images composed of 1.6 million pixels (this is the meaning of the expression 1.6 megapixels), carried an onboard memory of 16megabytes, and had an average cost higher than 10,000 U.S. dollars. At the time this book is being written, the best models are close to or even above 8 megapixels, have internal memories of one gigabyte and they cost around 1,000 U.S. dollars. In other words, while resolution and memory capacity have been multiplied by around five and fifty, respectively, the price has been divided by more than ten. Similar trends can be observed in all other kinds of digital devices including videocameras, cellular phones, mp3 players, personal digital assistants (PDA), etc. As a result, large amounts of digital material are being accumulated and need to be managed effectively in order to avoid the problem of information overload.},
author = {Camastra, Francesco},
doi = {10.1117/1.3152242},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Camastra - 2009 - Machine Learning for Audio, Image and Video Analysis.pdf:pdf},
issn = {1017-9909},
journal = {Journal of Electronic Imaging},
number = {2},
pages = {029901},
title = {{Machine Learning for Audio, Image and Video Analysis}},
volume = {18},
year = {2009}
}
@article{Fischer2003,
author = {Fischer, Julia and Hammerschmidt, Kurt and Cheney, Dorothy L and Seyfarth, Robert M},
doi = {10.1121/1.1433807},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2003 - Acoustic features of male baboon loud calls Influences of context, age, and individuality.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
number = {1465-1474},
title = {{Acoustic features of male baboon loud calls: Influences of context, age, and individuality}},
volume = {111},
year = {2003}
}
@article{Stevenson2015,
author = {Stevenson, Ben C and Borchers, David L and Altwegg, Res and Swift, J and Gillespie, Douglas M and Measey, G John},
doi = {10.1111/2041-210X.12291},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stevenson et al. - 2015 - A general framework for animal density estimation from acoustic detections across a fixed microphone array.pdf:pdf},
journal = {Methods in Ecology and Evolution},
pages = {38--48},
title = {{A general framework for animal density estimation from acoustic detections across a fixed microphone array}},
volume = {6},
year = {2015}
}
@article{Edwards2017,
author = {Edwards, Bryn},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edwards - 2017 - Using bioacoustics to assess the impacts of forest fire on primates .pdf:pdf},
number = {September},
title = {{Using bioacoustics to assess the impacts of forest fire on primates .}},
year = {2017}
}
@book{Bradbury2011,
author = {Bradbury, Jack and Vehrencamp, Sandra},
edition = {2},
publisher = {OUP, USA},
title = {{Principles of Animal Communication}},
year = {2011}
}
@techreport{TheRoy2003,
author = {Society, The Royal},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Society - 2003 - Measuring biodiversity for conservation.pdf:pdf},
pages = {1--65},
title = {{Measuring biodiversity for conservation}},
year = {2003}
}
@article{Accepts2008,
author = {Accepts, J V I and Society, American and Authors, Listed and Reserved, All Rights},
doi = {10.1128/JVI.00721-08},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Accepts et al. - 2008 - 强光胁迫下外源 N O对霍山石斛叶绿素荧光和抗氧 化系统的影响.pdf:pdf},
journal = {Microbiology},
number = {June},
title = {{强光胁迫下外源 N O对霍山石斛叶绿素荧光和抗氧 化系统的影响}},
volume = {4},
year = {2008}
}
@article{Hill2018,
abstract = {Introduction: D-dimer assay, generally evaluated according to cutoff points calibrated for VTE exclusion, is used to estimate the individual risk of recurrence after a first idiopathic event of venous thromboembolism (VTE). Methods: Commercial D-dimer assays, evaluated according to predetermined cutoff levels for each assay, specific for age (lower in subjects {\textless}70 years) and gender (lower in males), were used in the recent DULCIS study. The present analysis compared the results obtained in the DULCIS with those that might have been had using the following different cutoff criteria: traditional cutoff for VTE exclusion, higher levels in subjects aged ≥60 years, or age multiplied by 10. Results: In young subjects, the DULCIS low cutoff levels resulted in half the recurrent events that would have occurred using the other criteria. In elderly patients, the DULCIS results were similar to those calculated for the two age-adjusted criteria. The adoption of traditional VTE exclusion criteria would have led to positive results in the large majority of elderly subjects, without a significant reduction in the rate of recurrent event. Conclusion: The results confirm the usefulness of the cutoff levels used in DULCIS.},
author = {Hill, Andrew P. and Prince, Peter and {Pi{\~{n}}a Covarrubias}, Evelyn and Doncaster, C. Patrick and Snaddon, Jake L. and Rogers, Alex},
doi = {10.1111/2041-210X.12955},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hill et al. - 2018 - AudioMoth Evaluation of a smart open acoustic device for monitoring biodiversity and the environment.pdf:pdf},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {acoustic monitoring,biodiversity monitoring,ecosystem management,gunshot detection,open science,open-source hardware,open-source software},
number = {5},
pages = {1--13},
title = {{AudioMoth: Evaluation of a smart open acoustic device for monitoring biodiversity and the environment}},
volume = {9},
year = {2018}
}
@article{Aquino2013,
abstract = {The white-fronted spider monkey, Ateles belzebuth, is listed as 'Endangered' according to the IUCN classification. In Peru it is found in the departments of Loreto, San Mart{\'{i}}n, Amazonas and Cajamarca, but detailed data on its geographic distribution, population densities and conservation status are scarce. In order to obtain such information, we conducted transect censuses on the R{\'{i}}o Aushiri and R{\'{i}}o San Antonio (right bank of R{\'{i}}o Napo), and between the R{\'{i}}o Curaray and the R{\'{i}}o Arabela and R{\'{i}}o Nashi{\~{n}}o, respectively, and made additional explorations on the northern and southern banks of the R{\'{i}}o Mara{\~{n}}{\'{o}}n. We obtained 48 sightings along 761 km of census transect. Group size and population densities were lower in an area with high hunting pressure compared to areas with medium or low hunting pressure. Besides hunting, increasing deforestation is a major threat to the survival of A. belzebuth in Peruvian Amazonia.},
author = {Aquino, Rolando and Cornejo, Fanny M. and Pezo, Etersit and Heymann, Eckhard W.},
doi = {10.1159/000345549},
file = {:home/jacob/Documents/Project/Data/Papers/345549.pdf:pdf},
issn = {00155713},
journal = {Folia Primatologica},
keywords = {Ateles belzebuth,Ateles chamek,Conservation,Geographic distribution,Group size,Population density,Sympatry},
number = {1},
pages = {1--10},
title = {{Distribution and abundance of white-fronted spider monkeys, Ateles belzebuth (atelidae), and threats to their survival in Peruvian Amazonia}},
volume = {84},
year = {2013}
}
@article{Clarke2010,
abstract = {The loud songs of gibbons (Hylobatidae) usually consist of a duet by the mated pair delivered each morning. These songs can transmit over a kilometre through dense forest habitat and therefore presumably play a role in long-distance communication. There is some evidence to suggest that gibbons use song in contexts other than their daily duets, such as predation, but these songs have not been well studied. Close- range communication is also relevant for gibbons, but these quieter calls have completely escaped any detailed observation. The responses of wild white-handed gibbons (Hylobates lar) to simulated visual and acoustic predators (tiger, clouded leopard, reticulated python and crested serpent eagle) were studied in Khao Yai National Park, Thailand to address the lack of empirical data about these important events. Little is known about gibbons' anti- predatory behaviour in general, and simulated predator encounters provided an opportunity to investigate these responses as well. Results showed that gibbons used song as part of their anti-predator strategy and that subtle combinatorial changes were meaningful to conspecifics. They also showed marked behavioural changes in the short-term, and some evidence of longer-term changes as well. Quiet calls were also part of the gibbons' response repertoire with the hoo call being particularly relevant. Hoos were used as a prelude to singing both normal duets and predator songs, but there were consistent differences between each context. Hoos were also delivered independently in a number of other contexts outside predation. When analysed, these hoos showed consistent contextual differences in a number of spectral parameters. Within the duet context, important contextual subtleties were evident also revealing a remarkable vocal plasticity. In addition, gibbons voluntarily attended to specific vocal elements of other gibbon duets, indicating that certain sequences are more pertinent than others. Results suggest both gibbon song and gibbon hoos are powerful communication tools that reliably reference external objects and events; this ability is also a critical feature of human language.},
author = {Clarke, Esther Anne Elizabeth},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clarke - 2010 - The Vocalisations and Anti-predatory Behaviour of Wild White-handed Gibbons ( Hylobates lar ) in Khao Yai National Park.pdf:pdf},
pages = {1--233},
title = {{The Vocalisations and Anti-predatory Behaviour of Wild White-handed Gibbons ( Hylobates lar ) in Khao Yai National Park , Thailand}},
year = {2010}
}
@article{Snaddon2017,
author = {Snaddon, Jake L. and Hill, Andrew P. and Prince, Peter and Rogers, Alex and {Pi{\~{n}}a Covarrubias}, Evelyn and Doncaster, C. Patrick},
doi = {10.1111/2041-210x.12955},
journal = {Methods in Ecology and Evolution},
number = {5},
pages = {1199--1211},
title = {{AudioMoth: Evaluation of a smart open acoustic device for monitoring biodiversity and the environment}},
volume = {9},
year = {2017}
}
@article{Kalan2015,
author = {Kalan, Ammie K and Mundry, Roger and Wagner, Oliver J J and Heinicke, Stefanie and Boesch, Christophe and K{\"{u}}hl, Hjalmar S},
doi = {10.1016/j.ecolind.2015.02.023},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalan et al. - 2015 - Towards the automated detection and occupancy estimation of primates using passive acoustic monitoring.pdf:pdf},
issn = {1470-160X},
journal = {Ecological Indicators},
pages = {217--226},
publisher = {Elsevier Ltd},
title = {{Towards the automated detection and occupancy estimation of primates using passive acoustic monitoring}},
volume = {54},
year = {2015}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun, Bengio, Hinton - 2015 - Deep learning （PPT).pdf:pdf},
isbn = {9780521835688},
issn = {0028-0836},
journal = {Nature 2015},
number = {7553},
pages = {436--444},
pmid = {10463930},
title = {{Deep learning （PPT)}},
url = {http://dx.doi.org/10.1038/nature14539},
volume = {521},
year = {2015}
}
@techreport{Guyon1997,
abstract = {We address the problem of determining what fraction of the training set should be reserved$\backslash$nas development test set or validation set. We determine that the ratio of the validation set size$\backslash$nover the training set size scales like the square root of two complexity parameters: the complexity$\backslash$nof the second level of inference (minimizing the validation error) over the complexity$\backslash$nof the first level of inference (minimizing the error rate on the training set).$\backslash$n$\backslash$nKeywords: Cross-validation; Learning...},
author = {Guyon, Isabelle},
booktitle = {AT{\&}T Bell Laboratories},
file = {:home/jacob/Downloads/6c05d46e061290fefff8b46d0ff161998677.pdf:pdf},
keywords = {cross-validation,experiment design,learning theory,machine learning,nition,pattern recog-,statistics,test set,training set,validation set},
pages = {1--11},
title = {{A scaling law for the validation-set training-set size ratio}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.1337{\&}rep=rep1{\&}type=pdf},
year = {1997}
}
@techreport{Browning2017,
abstract = {Wrege, as well as 8 participants who chose to remain anonymous. Funding for this report was provided by WWF-UK. WWF is one of the world's largest and most experienced independent conservation organizations, with over 5 million supporters and a global network active in more than 100 countries. WWF's mission is to stop the degredation of the planets natural environment and to build a future in which humans live in harmony with nature by conserving the worlds biological diversity, ensuring that the use of renewable natural resources is sustainable, and promoting the reduction of pollution and wasteful consumption. Cover Image: Transient Orca (Orcinus orca) calls recorded in Glacier Bay, Alaska {\textcopyright} V. Deecke},
author = {Browning, Ella and Gibb, Rory and Glover-Kapfer, Paul and Jones, Kate E.},
booktitle = {WWF Conservation Technology Series 1(2)},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Browning et al. - 2017 - Passive acoustic monitoring in ecology and conservation.pdf:pdf},
issn = {0964-6906},
pages = {1--75},
pmid = {11875046},
title = {{Passive acoustic monitoring in ecology and conservation}},
volume = {2},
year = {2017}
}
@article{Fischer2001,
author = {Fischer, Julia and Hammerschmidt, Kurt and Cheney, Dorothy L and Seyfarth, Robert M},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fischer et al. - 2001 - Acoustic Features of Female Chacma Baboon Barks.pdf:pdf},
journal = {Ethology},
pages = {33--54},
title = {{Acoustic Features of Female Chacma Baboon Barks}},
volume = {107},
year = {2001}
}
@article{Fristrup2012,
author = {Fristrup, Kurt M and Mennitt, Dan},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fristrup, Mennitt - 2012 - terrestrial environments . Hornworts.pdf:pdf},
journal = {History},
number = {July},
pages = {738--739},
title = {{terrestrial environments . Hornworts}},
volume = {8},
year = {2012}
}
@article{Tang2009,
abstract = {There are two important research topics in the field of Music Information Retrieval (MIR). One is how to improve the robustness of features and the other is how to speed up the retrieval process. This paper improved the algorithms which proposed by Shazam company in these two aspects. We improve the robustness of the system by a new audio finger-printing extraction using computer graphics, and the system can recognize the recordings which get in complex environment accurately. On the other hand, we propose a recursive search algorithm based on the confidence measure to improve the retrieval speed. Quantitative analysis of the opposite experiment verifies the improvement in the retrieval speed and accuracy.},
author = {Tang, Jie and Liu, Gang and Guo, Jun},
doi = {10.1109/IITAW.2009.110},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Liu, Guo - 2009 - Improved algorithms of music information retrieval based on audio fingerprint.pdf:pdf},
isbn = {9780769538600},
journal = {3rd International Symposium on Intelligent Information Technology Application Workshops, IITAW 2009},
keywords = {Audio fingerprinting,Computer vision,Recursive retrieval},
pages = {367--371},
title = {{Improved algorithms of music information retrieval based on audio fingerprint}},
year = {2009}
}
@article{Breebaart2013,
abstract = {Four audio feature sets are evaluated in their ability to differentiate five audio classes: pop- ular music, classical music, speech, noise and crowd noise. The feature sets include low-level signal properties, mel-frequency spectral coefficients, and two new sets based on perceptual models of hearing. The temporal behavior of the features is analyzed and parameterized and these parameters are included as additional features. Using a standard Gaussian framework for classification, results show that the temporal behavior of features is important for automatic audio classification. In addition, classification is better, on average, if based on features from models of auditory perception rather than on standard features.},
author = {Breebaart, Jeroen and McKinney, Martin F.},
doi = {10.1007/978-94-017-0703-9_6},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breebaart, McKinney - 2013 - Features for Audio Classification.pdf:pdf},
isbn = {9789401707039},
number = {October},
pages = {113--129},
title = {{Features for Audio Classification}},
year = {2013}
}
@article{Chiarucci2011,
abstract = {Although the maintenance of diversity of living systems is critical for ecosystem functioning, the accelerating pace of global change is threatening its preservation. Standardized methods for biodiversity assessment and monitoring are needed. Species diversity is one of the most widely adopted metrics for assessing patterns and processes of biodiversity, at both ecological and biogeographic scales. However, those perspectives differ because of the types of data that can be feasibly collected, resulting in differences in the questions that can be addressed. Despite a theoretical consensus on diversity metrics, standardized methods for its measurement are lacking, especially at the scales needed to monitor biodiversity for conservation and management purposes. We review the conceptual framework for species diversity, examine common metrics, and explore their use for biodiversity conservation and management. Key differences in diversity measures at ecological and biogeographic scales are the completeness of species lists and the ability to include information on species abundances. We analyse the major pitfalls and problems with quantitative measurement of species diversity, look at the use of weighting measures by phylogenetic distance, discuss potential solutions and propose a research agenda to solve the major existing problems.},
author = {Chiarucci, Alessandro and Bacaro, Giovanni and Scheiner, Samuel M.},
doi = {10.1098/rstb.2011.0065},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiarucci, Bacaro, Scheiner - 2011 - Old and new challenges in using species diversity for assessing biodiversity.pdf:pdf},
issn = {09628436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Biodiversity assessment,Biogeography,Diversity measurement,Ecology,Spatial scale},
number = {1576},
pages = {2426--2437},
title = {{Old and new challenges in using species diversity for assessing biodiversity}},
volume = {366},
year = {2011}
}
@article{Digby2013,
author = {Digby, Andrew and Towsey, Michael and Bell, Ben D and Teal, Paul D},
doi = {10.1111/2041-210X.12060},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Digby et al. - 2013 - A practical comparison of manual and autonomous methods for acoustic monitoring.pdf:pdf},
journal = {Methods},
pages = {675--683},
title = {{A practical comparison of manual and autonomous methods for acoustic monitoring}},
volume = {4},
year = {2013}
}
@article{Sueur2008,
abstract = {ABSTRACT We review Seewave, new software for analysing and synthesizing sounds. Seewave is free and works on a wide variety of operating systems as an extension of the R operating environment. Its current 67 functions allow the user to achieve time, amplitude and frequency analyses, to estimate quantitative differences between sounds, and to generate new sounds for playback experiments. Thanks to its implementation in the R environment, Seewave is fully modular. All functions can be combined for complex data acquisition and graphical output, they can be part of important scripts for batch processing and they can be modified ad libitum. New functions can also be written, making Seewave a truly open-source tool.},
author = {Sueur, J and Aubin, T and Simons, C},
doi = {10.1080/09524622.2008.9753600},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sueur, Aubin, Simons - 2008 - Seewave, a Free Modular Tool for Sound Analysis and Synthesis.pdf:pdf},
isbn = {3527312102},
issn = {03771237},
journal = {Medical Journal Armed Forces India},
number = {3},
pages = {241},
title = {{Seewave, a Free Modular Tool for Sound Analysis and Synthesis}},
volume = {58},
year = {2008}
}
@article{Salamon2017,
abstract = {The ability of deep convolutional neural networks (CNN) to learn discriminative spectro-temporal patterns makes them well suited to environmental sound classification. However, the relative scarcity of labeled data has impeded the exploitation of this family of high-capacity models. This study has two primary contributions: first, we propose a deep convolutional neural network architecture for environmental sound classification. Second, we propose the use of audio data augmentation for overcoming the problem of data scarcity and explore the influence of different augmentations on the performance of the proposed CNN architecture. Combined with data augmentation, the proposed model produces state-of-the-art results for environmental sound classification. We show that the improved performance stems from the combination of a deep, high-capacity model and an augmented training set: this combination outperforms both the proposed CNN without augmentation and a "shallow" dictionary learning model with augmentation. Finally, we examine the influence of each augmentation on the model's classification accuracy for each class, and observe that the accuracy for each class is influenced differently by each augmentation, suggesting that the performance of the model could be improved further by applying class-conditional data augmentation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1608.04363v2},
author = {Salamon, Justin and Bello, Juan Pablo},
doi = {10.1109/LSP.2017.2657381},
eprint = {arXiv:1608.04363v2},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {Deep convolutional neural networks (CNNs),deep learning,environmental sound classification,urban sound dataset},
number = {3},
pages = {279--283},
title = {{Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification}},
volume = {24},
year = {2017}
}
@article{Walters2012,
abstract = {1. Acoustic methods are used increasingly to survey and monitor bat populations. However, the use of acoustic methods at continental scales can be hampered by the lack of standardized and objective methods to identify all species recorded. This makes comparable continent-wide monitoring difficult, impeding progress towards developing biodiversity indicators, transboundary conservation programmes and monitoring species distribution changes. 2. Here we developed a continental-scale classifier for acoustic identification of bats, which can be used throughout Europe to ensure objective, consistent and comparable species identifications. We selected 1350 full-spectrum reference calls from a set of 15 858 calls of 34 European species, from EchoBank, a global echolocation call library. We assessed 24 call parameters to evaluate how well they distinguish between species and used the 12 most useful to train a hierarchy of ensembles of artificial neural networks to distinguish the echolocation calls of these bat species. 3. Calls are first classified to one of five call-type groups, with a median accuracy of 976{\%}. The median species-level classification accuracy is 837{\%}, providing robust classification for most European species, and an estimate of classification error for each species. 4. These classifiers were packaged into an online tool, iBatsID, which is freely available, enabling anyone to classify European calls in an objective and consistent way, allowing standardized acoustic identification across the continent. 5. Synthesis and applications. iBatsID is the first freely available and easily accessible continental- scale bat call classifier, providing the basis for standardized, continental acoustic bat monitoring in Europe. This method can provide key information to managers and conservation planners on distribution changes and changes in bat species activity through time.},
author = {Walters, Charlotte L. and Freeman, Robin and Collen, Alanna and Dietz, Christian and {Brock Fenton}, M. and Jones, Gareth and Obrist, Martin K. and Puechmaille, S{\'{e}}bastien J. and Sattler, Thomas and Siemers, Bj{\"{o}}rn M. and Parsons, Stuart and Jones, Kate E.},
doi = {10.1111/j.1365-2664.2012.02182.x},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walters et al. - 2012 - A continental-scale tool for acoustic identification of European bats.pdf:pdf},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {Acoustic monitoring,Chiroptera,Classification,Echolocation,Ensembles of artificial neural networks,Indicator species,Species identification},
number = {5},
pages = {1064--1074},
title = {{A continental-scale tool for acoustic identification of European bats}},
volume = {49},
year = {2012}
}
@phdthesis{Butler2018,
author = {Butler, Duncan},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Butler - 2018 - Creating a deep-learning automated audio detection system for Geoffroy ' s spider monkey , Ateles geoffroyi.pdf:pdf},
pages = {1--22},
school = {Imperial College London},
title = {{Creating a deep-learning automated audio detection system for Geoffroy ' s spider monkey , Ateles geoffroyi}},
year = {2018}
}
@article{Prince2019,
abstract = {{\textless}p{\textgreater}Conservation researchers require low-cost access to acoustic monitoring technology. However, affordable tools are often constrained to short-term studies due to high energy consumption and limited storage. To enable long-term monitoring, energy and space efficiency must be improved on such tools. This paper describes the development and deployment of three acoustic detection algorithms that reduce the power and storage requirements of acoustic monitoring on affordable, open-source hardware. The algorithms aim to detect bat echolocation, to search for evidence of an endangered cicada species, and also to collect evidence of poaching in a protected nature reserve. The algorithms are designed to run on AudioMoth: a low-cost, open-source acoustic monitoring device, developed by the authors and widely adopted by the conservation community. Each algorithm addresses a detection task of increasing complexity, implementing extra analytical steps to account for environmental conditions such as wind, analysing samples multiple times to prevent missed events, and incorporating a hidden Markov model for sample classification in both the time and frequency domain. For each algorithm, we report on real-world deployments carried out with partner organisations and also benchmark the hidden Markov model against a convolutional neural network, a deep-learning technique commonly used for acoustics. The deployments demonstrate how acoustic detection algorithms extend the use of low-cost, open-source hardware and facilitate a new avenue for conservation researchers to perform large-scale monitoring.{\textless}/p{\textgreater}},
author = {Prince, Peter and Hill, Andrew and {Pi{\~{n}}a Covarrubias}, Evelyn and Doncaster, Patrick and Snaddon, Jake L. and Rogers, Alex},
doi = {10.3390/s19030553},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prince et al. - 2019 - Deploying Acoustic Detection Algorithms on Low-Cost, Open-Source Acoustic Sensors for Environmental Monitoring.pdf:pdf},
issn = {14248220},
journal = {Sensors (Basel, Switzerland)},
keywords = {acoustics,bioacoustics,conservation,ecology,machine learning},
number = {3},
pages = {1--23},
title = {{Deploying Acoustic Detection Algorithms on Low-Cost, Open-Source Acoustic Sensors for Environmental Monitoring}},
volume = {19},
year = {2019}
}
@article{Barlow2016,
abstract = {{\textcopyright} 2016 Macmillan Publishers Limited. All rights reserved.  Concerted political attention has focused on reducing deforestation, and this remains the cornerstone of most biodiversity conservation strategies. However, maintaining forest cover may not reduce anthropogenic forest disturbances, which are rarely considered in conservation programmes. These disturbances occur both within forests, including selective logging and wildfires, and at the landscape level, through edge, area and isolation effects. Until now, the combined effect of anthropogenic disturbance on the conservation value of remnant primary forests has remained unknown, making it impossible to assess the relative importance of forest disturbance and forest loss. Here we address these knowledge gaps using a large data set of plants, birds and dung beetles (1,538, 460 and 156 species, respectively) sampled in 36 catchments in the Brazilian state of Par{\'{a}}. Catchments retaining more than 69-80{\%} forest cover lost more conservation value from disturbance than from forest loss. For example, a 20{\%} loss of primary forest, the maximum level of deforestation allowed on Amazonian properties under Brazil's Forest Code, resulted in a 39-54{\%} loss of conservation value: 96-171{\%} more than expected without considering disturbance effects. We extrapolated the disturbance-mediated loss of conservation value throughout Par{\'{a}}, which covers 25{\%} of the Brazilian Amazon. Although disturbed forests retained considerable conservation value compared with deforested areas, the toll of disturbance outside Par{\'{a}}'s strictly protected areas is equivalent to the loss of 92,000-139,000 km 2 of primary forest. Even this lowest estimate is greater than the area deforested across the entire Brazilian Amazon between 2006 and 2015 (ref. 10). Species distribution models showed that both landscape and within-forest disturbances contributed to biodiversity loss, with the greatest negative effects on species of high conservation and functional value. These results demonstrate an urgent need for policy interventions that go beyond the maintenance of forest cover to safeguard the hyper-diversity of tropical forest ecosystems.},
author = {Barlow, Jos and Lennox, Gareth D. and Ferreira, Joice and Berenguer, Erika and Lees, Alexander C. and Nally, Ralph Mac and Thomson, James R. and Ferraz, Silvio Frosini De Barros and Louzada, Julio and Oliveira, Victor Hugo Fonseca and Parry, Luke and {Ribeiro De Castro Solar}, Ricardo and Vieira, Ima C.G. and Araga{\~{o}}, Luiz E.O.C. and Begotti, Rodrigo Anzolin and Braga, Rodrigo F. and Cardoso, Thiago Moreira and Jr, Raimundo Cosme De Oliveira and Souza, Carlos M. and Moura, N{\'{a}}rgila G. and Nunes, S{\^{a}}mia Serra and Siqueira, Joa{\~{o}} Victor and Pardini, Renata and Silveira, Juliana M. and Vaz-De-Mello, Fernando Z. and Veiga, Ruan Carlo Stulpen and Venturieri, Adriano and Gardner, Toby A.},
doi = {10.1038/nature18326},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barlow et al. - 2016 - Anthropogenic disturbance in tropical forests can double biodiversity loss from deforestation.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7610},
pages = {144--147},
publisher = {Nature Publishing Group},
title = {{Anthropogenic disturbance in tropical forests can double biodiversity loss from deforestation}},
url = {http://dx.doi.org/10.1038/nature18326},
volume = {535},
year = {2016}
}
@book{Russ2013,
author = {Russ, Jon},
edition = {1},
publisher = {Pelagic Publishing},
title = {{British Bat Calls: A Guide to Species Identification}},
year = {2013}
}
@article{Snaddon2017,
author = {Snaddon, Jake L and Hill, Andrew P and Prince, Peter and Rogers, Alex and {Pi{\~{n}}a Covarrubias}, Evelyn and Doncaster, C Patrick},
doi = {10.1111/2041-210x.12955},
journal = {Methods in Ecology and Evolution},
number = {5},
pages = {1199--1211},
title = {{AudioMoth: Evaluation of a smart open acoustic device for monitoring biodiversity and the environment}},
volume = {9},
year = {2017}
}
@article{Merchant2015,
abstract = {1. Many organisms depend on sound for communication, predator/prey detection and navigation. The acoustic environment can therefore play an important role in ecosystem dynamics and evolution. A growing number of studies are documenting acoustic habitats and their influences on animal development, behaviour, physiology and spatial ecology, which has led to increasing demand for passive acoustic monitoring (PAM) expertise in the life sciences. However, as yet, there has been no synthesis of data processing methods for acoustic habitat monitoring, which presents an unnecessary obstacle to would-be PAM analysts. 2. Here, we review the signal processing techniques needed to produce calibrated measurements of terrestrial and aquatic acoustic habitats. We include a supplemental tutorial and template computer codes in matlab and r, which give detailed guidance on how to produce calibrated spectrograms and statistical analyses of sound levels. Key metrics and terminology for the characterisation of biotic, abiotic and anthropogenic sound are covered, and their application to relevant monitoring scenarios is illustrated through example data sets. To inform study design and hardware selection, we also include an up-to-date overview of terrestrial and aquatic PAM instruments. 3. Monitoring of acoustic habitats at large spatiotemporal scales is becoming possible through recent advances in PAM technology. This will enhance our understanding of the role of sound in the spatial ecology of acoustically sensitive species and inform spatial planning to mitigate the rising influence of anthropogenic noise in these ecosystems. As we demonstrate in this work, progress in these areas will depend upon the application of consistent and appropriate PAM methodologies.},
author = {Merchant, Nathan D. and Fristrup, Kurt M. and Johnson, Mark P. and Tyack, Peter L. and Witt, Matthew J. and Blondel, Philippe and Parks, Susan E.},
doi = {10.1111/2041-210X.12330},
file = {:home/jacob/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merchant et al. - 2015 - Measuring acoustic habitats.pdf:pdf},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Acoustic ecology,Ambient noise,Anthropogenic noise,Bioacoustics,Ecoacoustics,Habitat monitoring,Passive acoustic monitoring,Remote sensing,Soundscape},
number = {3},
pages = {257--265},
title = {{Measuring acoustic habitats}},
volume = {6},
year = {2015}
}
